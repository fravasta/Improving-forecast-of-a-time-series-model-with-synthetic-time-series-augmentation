{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TIME GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, TimeDistributed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simuliamo una serie temporale semplice\n",
    "def generate_synthetic_data(n_samples=1000, seq_len=24):\n",
    "    x = np.linspace(0, 50, n_samples)\n",
    "    y = np.sin(x) + np.random.normal(0, 0.1, n_samples)  # Sinusoide con rumore\n",
    "    sequences = [y[i: i + seq_len] for i in range(n_samples - seq_len)]\n",
    "    return np.array(sequences)\n",
    "\n",
    "# Normalizziamo i dati\n",
    "scaler = MinMaxScaler()\n",
    "data = generate_synthetic_data()\n",
    "data = scaler.fit_transform(data.reshape(-1, 1)).reshape(data.shape)\n",
    "\n",
    "# TimeGAN components\n",
    "class TimeGAN:\n",
    "    def __init__(self, seq_len, feature_dim, hidden_dim=24, batch_size=128):\n",
    "        self.seq_len = seq_len\n",
    "        self.feature_dim = feature_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Generator\n",
    "        self.generator = tf.keras.Sequential([\n",
    "            LSTM(self.hidden_dim, return_sequences=True, input_shape=(self.seq_len, self.feature_dim)),\n",
    "            TimeDistributed(Dense(self.feature_dim, activation='tanh'))\n",
    "        ])\n",
    "        \n",
    "        # Discriminator\n",
    "        self.discriminator = tf.keras.Sequential([\n",
    "            LSTM(self.hidden_dim, return_sequences=False, input_shape=(self.seq_len, self.feature_dim)),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        # Autoencoder (Embedding network)\n",
    "        self.autoencoder = tf.keras.Sequential([\n",
    "            LSTM(self.hidden_dim, return_sequences=True, input_shape=(self.seq_len, self.feature_dim)),\n",
    "            LSTM(self.hidden_dim, return_sequences=True),\n",
    "            TimeDistributed(Dense(self.feature_dim))\n",
    "        ])\n",
    "        \n",
    "        # Compile\n",
    "        self.generator.compile(optimizer='adam', loss='mse')\n",
    "        self.discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    def train(self, data, epochs=1000):\n",
    "        for epoch in range(epochs):\n",
    "            idx = np.random.randint(0, data.shape[0], self.batch_size)\n",
    "            real_samples = data[idx]\n",
    "            noise = np.random.normal(0, 1, (self.batch_size, self.seq_len, self.feature_dim))\n",
    "            fake_samples = self.generator.predict(noise)\n",
    "            \n",
    "            # Train discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(real_samples, np.ones((self.batch_size, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(fake_samples, np.zeros((self.batch_size, 1)))\n",
    "            d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "            \n",
    "            # Train generator\n",
    "            g_loss = self.generator.train_on_batch(noise, real_samples)\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}: D Loss: {d_loss:.4f}, G Loss: {g_loss:.4f}\")\n",
    "\n",
    "    def generate(self, num_samples=100):\n",
    "        noise = np.random.normal(0, 1, (num_samples, self.seq_len, self.feature_dim))\n",
    "        return self.generator.predict(noise)\n",
    "\n",
    "# Training TimeGAN\n",
    "seq_len = data.shape[1]\n",
    "feature_dim = 1  # Un'unica feature (può essere esteso per più feature)\n",
    "timegan = TimeGAN(seq_len, feature_dim)\n",
    "timegan.train(data, epochs=1000)\n",
    "\n",
    "# Generazione di nuove serie temporali\n",
    "synthetic_data = timegan.generate(100)\n",
    "\n",
    "# Visualizzazione\n",
    "plt.plot(synthetic_data[0], label=\"Serie Temporale Generata\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
